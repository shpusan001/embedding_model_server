from fastapi import FastAPI, Query, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from transformers import AutoTokenizer, AutoModel
from pydantic import BaseModel
from typing import List
import torch
import time
import os

app = FastAPI()
security = HTTPBearer()

# API Key í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’ ì œê³µ)
API_KEY = os.getenv("EMBEDDING_API_KEY", "default-embedding-key-2024")
if API_KEY == "default-embedding-key-2024":
    print("âš ï¸  ê¸°ë³¸ API í‚¤ë¥¼ ì‚¬ìš©ì¤‘ì…ë‹ˆë‹¤. ë³´ì•ˆì„ ìœ„í•´ EMBEDDING_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)):
    if credentials.credentials != API_KEY:
        raise HTTPException(status_code=401, detail="Invalid API key")
    return credentials.credentials

MODEL_PATH = "./local_models/labse/models--sentence-transformers--LaBSE/snapshots/836121a0533e5664b21c7aacc5d22951f2b8b25b"  # âœ… ë¡œì»¬ ëª¨ë¸ ê²½ë¡œ

print("ğŸŸ¡ ëª¨ë¸ ë¡œë”© ì‹œì‘...")

start = time.time()
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
print(f"âœ… Tokenizer ë¡œë”© ì™„ë£Œ ({time.time() - start:.2f}s)")

start = time.time()
model = AutoModel.from_pretrained(MODEL_PATH)
print(f"âœ… Model ë¡œë”© ì™„ë£Œ ({time.time() - start:.2f}s)")

class BulkEmbedRequest(BaseModel):
    texts: List[str]

@app.get("/")
async def home():
    return {"message": "Hello World"}

@app.get("/embed")
async def embed(text: str = Query(..., min_length=1), api_key: str = Depends(verify_api_key)):
    try:
        print(f"ğŸ“© ìš”ì²­ ë„ì°©: {text}")
        inputs = tokenizer(text, return_tensors="pt")
        with torch.no_grad():
            outputs = model(**inputs)
            pooled = outputs.last_hidden_state.mean(dim=1)
        print("âœ… ì„ë² ë”© ì™„ë£Œ")
        return {"embedding": pooled[0].tolist()}
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"error": str(e)}

@app.post("/embed/bulk")
async def embed_bulk(request: BulkEmbedRequest, api_key: str = Depends(verify_api_key)):
    try:
        print(f"ğŸ“© ë²Œí¬ ìš”ì²­ ë„ì°©: {len(request.texts)}ê°œ í…ìŠ¤íŠ¸")
        
        # ë°°ì¹˜ë¡œ í† í¬ë‚˜ì´ì§• (íš¨ìœ¨ì )
        inputs = tokenizer(request.texts, return_tensors="pt", padding=True, truncation=True)
        
        with torch.no_grad():
            outputs = model(**inputs)
            # ê° í…ìŠ¤íŠ¸ë³„ë¡œ í‰ê·  í’€ë§
            pooled = outputs.last_hidden_state.mean(dim=1)
        
        # ê° ì„ë² ë”©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        embeddings = [embedding.tolist() for embedding in pooled]
        
        print(f"âœ… ë²Œí¬ ì„ë² ë”© ì™„ë£Œ: {len(embeddings)}ê°œ")
        return {"embeddings": embeddings}
    except Exception as e:
        print(f"âŒ ë²Œí¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}
